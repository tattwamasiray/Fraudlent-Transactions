{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39194c9b",
   "metadata": {},
   "source": [
    "# This code is to go in the flask file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d94ad",
   "metadata": {},
   "source": [
    "# 1. Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d28de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import numpy as np # For numerical operations and calculations\n",
    "import pandas as pd # To read and manipulate the lending data as a dataframe\n",
    "from pathlib import Path # To specify the the file path for reading the csv file\n",
    "from sklearn.preprocessing import StandardScaler # To scale the data\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f68904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the credit card transaction data file from the resources folder into a pandas dataframe\n",
    "# sample_df will be used to append is_fraud predictions \n",
    "sample_df = pd.read_csv(Path(\"sample1.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f1d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the sample dataframe -\n",
    "fraud_df = sample_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f89a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the cc_num and trans_num columns as credit numbers are randomly generated by the banks and \n",
    "# have no link to whether fraud will be committed\n",
    "fraud_df.drop(['cc_num','trans_num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49cc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes of each column\n",
    "# fraud_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff7a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'trans_date_trans_time' from object to date time format\n",
    "fraud_df['trans_date_trans_time'] = pd.to_datetime(fraud_df['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3269d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort transaction date and time in ascending order\n",
    "fraud_df = fraud_df.sort_values(by='trans_date_trans_time', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ded178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows to generate based on rows in sample file uploaded\n",
    "num_rows = len(fraud_df)\n",
    "\n",
    "# Initialize 'is_fraud' column with 0\n",
    "fraud_df['is_fraud'] = 0\n",
    "\n",
    "# Set 'is_fraud' to 1 for the first transaction\n",
    "fraud_df.loc[0, 'is_fraud'] = 1\n",
    "\n",
    "# Set 'is_fraud' to 1 for transactions every 7 days\n",
    "for i in range(1, len(fraud_df)):\n",
    "    time_difference = fraud_df['trans_date_trans_time'].iloc[i] - fraud_df['trans_date_trans_time'].iloc[i - 1]\n",
    "    if time_difference >= timedelta(days=7):\n",
    "        fraud_df.loc[i, 'is_fraud'] = 1\n",
    "\n",
    "fraud_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968860a0",
   "metadata": {},
   "source": [
    "## 2. Convert DateTime and Time columns into Unix Timestamps\n",
    "### columns 'trans_date_trans_time'  and 'dob' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9370e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'trans_date_trans_time' column to datetime objects\n",
    "fraud_df['trans_date_trans_time'] = pd.to_datetime(fraud_df['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Convert the 'trans_date_trans_time' column to Unix timestamps\n",
    "fraud_df['trans_date_trans_time'] = (fraud_df['trans_date_trans_time'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "# Convert the 'dob' column to datetime objects\n",
    "fraud_df['dob'] = pd.to_datetime(fraud_df['dob'], format='%Y-%m-%d')\n",
    "\n",
    "# Convert the 'dob' column to Unix timestamps\n",
    "fraud_df['dob'] = (fraud_df['dob'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e16e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numeric columns.\n",
    "# Scaling the data is necessary to ensure that features with different units or magnitudes have an equal \n",
    "# influence on machine learning algorithms and to enable efficient convergence.\n",
    "\n",
    "# Define the columns you want to scale (assuming they are all numeric)\n",
    "columns_to_scale = ['trans_date_trans_time', 'amt','zip','lat','long','city_pop','dob','unix_time','merch_lat','merch_long']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on your data and transform the specified columns\n",
    "fraud_df[columns_to_scale] = scaler.fit_transform(fraud_df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762ef0b",
   "metadata": {},
   "source": [
    "## 3. Implement target encoding for the individual categorical features and the 'is_fraud' target variable (except gender column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c6cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement target encoding for the 'merchant' feature and the 'is_fraud' target variable\n",
    "\n",
    "# Calculate the mean 'is_fraud' for each 'merchant'\n",
    "target_mean = fraud_df.groupby('merchant')['is_fraud'].mean()\n",
    "\n",
    "# Replace merchant column with the target encoding\n",
    "fraud_df['merchant'] = fraud_df['merchant'].map(target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef7ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement target encoding for the 'category' feature and the 'is_fraud' target variable\n",
    "\n",
    "# Calculate the mean 'is_fraud' for each 'job'\n",
    "target_mean = fraud_df.groupby('category')['is_fraud'].mean()\n",
    "\n",
    "# Replace category column with the target encoding\n",
    "fraud_df['category'] = fraud_df['category'].map(target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1999d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement target encoding for the 'first' feature and the 'is_fraud' target variable\n",
    "\n",
    "# Calculate the mean 'is_fraud' for each 'first'\n",
    "target_mean = fraud_df.groupby('first')['is_fraud'].mean()\n",
    "\n",
    "# Replace first column with the target encoding\n",
    "fraud_df['first'] = fraud_df['first'].map(target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a209ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement target encoding for the 'last' feature and the 'is_fraud' target variable\n",
    "\n",
    "# Calculate the mean 'is_fraud' for each 'last'\n",
    "target_mean = fraud_df.groupby('last')['is_fraud'].mean()\n",
    "\n",
    "# Replace last column with the target encoding\n",
    "fraud_df['last'] = fraud_df['last'].map(target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef2c4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement target encoding for the 'street' feature and the 'is_fraud' target variable\n",
    "\n",
    "# Calculate the mean 'is_fraud' for each 'street'\n",
    "target_mean = fraud_df.groupby('street')['is_fraud'].mean()\n",
    "\n",
    "# Replace street column with the target encoding\n",
    "fraud_df['street'] = fraud_df['street'].map(target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "668a9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement target encoding for the 'city' feature and the 'is_fraud' target variable\n",
    "\n",
    "# Calculate the mean 'is_fraud' for each 'city'\n",
    "target_mean = fraud_df.groupby('city')['is_fraud'].mean()\n",
    "\n",
    "# Replace city column with the target encoding\n",
    "fraud_df['city'] = fraud_df['city'].map(target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9eed307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement target encoding for the 'state' feature and the 'is_fraud' target variable\n",
    "\n",
    "# Calculate the mean 'is_fraud' for each 'state'\n",
    "target_mean = fraud_df.groupby('state')['is_fraud'].mean()\n",
    "\n",
    "# Replace state column with the target encoding\n",
    "fraud_df['state'] = fraud_df['state'].map(target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6582e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement target encoding for the 'job' feature and the 'is_fraud' target variable\n",
    "\n",
    "# Calculate the mean 'is_fraud' for each 'job'\n",
    "target_mean = fraud_df.groupby('job')['is_fraud'].mean()\n",
    "\n",
    "# Replace job column with the target encoding\n",
    "fraud_df['job'] = fraud_df['job'].map(target_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f6743",
   "metadata": {},
   "source": [
    "## 4. Convert gender feature from categorical to numerical (male-1, female-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e99f61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"M\" with 1 and \"F\" with 0 in the \"gender\" column\n",
    "fraud_df['gender'] = fraud_df['gender'].replace({'M': 1, 'F': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e182589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop is_fraud column\n",
    "fraud_df.drop(['is_fraud'], axis=1, inplace=True)\n",
    "\n",
    "# File is now ready for machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dd099f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fraud_df to CSV file\n",
    "#file_path = \"sample1_encoded.csv\"\n",
    "\n",
    "# Use the to_csv method to export the DataFrame to a CSV file\n",
    "#fraud_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f49acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
